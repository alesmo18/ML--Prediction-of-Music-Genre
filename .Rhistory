glimpse(music_dataset)
# Caricamento dataset da file csv
music_dataset <- read.csv("music_genre.csv", header = TRUE)
setwd("~/ML-Progetto-MusicGenre")
library(MLmetrics)
library(FactoMineR)
library(factoextra)
library(randomForest)
library(C50)
library(caret)
library(e1071)
library(dplyr)
library(corrplot)
library(neuralnet)
library(tidyr)
library(magrittr)
library(tidyverse)
# Caricamento dataset da file csv
music_dataset <- read.csv("music_genre.csv", header = TRUE)
# Dimensione dataset
dim(music_dataset)
# Stampa di n righe random del dataset
sample_n(music_dataset, 5)
summary(music_dataset)
# Verifica e rimozione di eventuali righe duplicate e con valori NA nelle colonne
music_dataset <- na.omit(music_dataset)
music_dataset <- music_dataset[complete.cases(music_dataset),]
dim(music_dataset[rowSums(is.na(music_dataset)) > 0, ])
music_dataset %>% drop_na()
# Reset dell'index dopo la cancellazione di alcune righe
row.names(music_dataset) <- NULL
dim(music_dataset)
# Labels del genere musicale e distrubuzione dei generi musicali nel df
lables <- unique(music_dataset$music_genre)
table(music_dataset$music_genre)
# Rimozione delle colonne rappresentanti feature inutili alla classificazione con i modelli
# quindi, principalmente si eliminano i caratteri qualitativi che non saranno trasformati in factors
# in particolare si eliminano le features che non influenzerebbero la classificazione
music_dataset <- within(music_dataset, rm('instance_id', 'track_name', 'obtained_date', 'index', 'artist_name'))
dim(music_dataset)
sample_n(music_dataset, 5)
# Codifica delle colonne con valori qualitativi attraverso factors(x, levels)
# Per utilizzare nei modelli le colonne "key" e "mode" si codificano mappandone i valori
# al fine di renderli valori numerici
# "mode" - codifica in valori pari a 1 o 2 (majior o minor)
# "key" - codifica fino a 12 valori (suoni note musicali)
encode_ordinal <- function(x, order = unique(x)) {
x <- as.numeric(factor(x, levels = order, exclude = NULL))
x
}
music_dataset[["key"]] <- encode_ordinal(music_dataset[["key"]])
head(music_dataset)
music_dataset[["mode"]] <- encode_ordinal(music_dataset[["mode"]])
head(music_dataset)
music_dataset$tempo <- as.double(music_dataset$tempo)
head(music_dataset)
# Eliminazione delle righe con feature: duration_ms pari a -1
# quindi dei brani con durata non presente nel dataset
music_dataset <- filter(music_dataset, duration_ms != -1)
# Trasformazione delle lables da type: chr a type: factor
music_dataset$music_genre = as.factor(music_dataset$music_genre)
str(music_dataset)
dim(music_dataset)
# Verifica e rimozione dei valori NA dopo la codifica delle features "key" e "mode"
music_dataset <- na.omit(music_dataset)
music_dataset <- music_dataset[complete.cases(music_dataset),]
dim(music_dataset[rowSums(is.na(music_dataset)) > 0, ])
music_dataset %>% drop_na()
# Normalizzazione del dataset per tutte le features con dominio numerico
process <- preProcess(as.data.frame(music_dataset), method=c("center", "scale"))
music_dataset <- predict(process, as.data.frame(music_dataset))
glimpse(music_dataset)
summary(music_dataset)
table(music_dataset$music_genre)
# Plotting ed eliminazione degli outliers
# plotting per ogni colonna
for (i in colnames(music_dataset)){
if(is.numeric(music_dataset[[i]])){
boxplot(music_dataset[[i]],
main = paste("Boxplot", i),
xlab = "values",
ylab =  i,
col = "cyan",
border = "blue",
horizontal = TRUE,
notch = FALSE
)}}
head(music_dataset)
z_scores = as.data.frame(sapply(music_dataset, function(music_dataset) (abs(music_dataset-mean(music_dataset))/sd(music_dataset))))
no_outliers = z_scores[!rowSums(z_scores>3), ]
head(no_outliers)
# Shuffle del dataset
music_dataset = music_dataset[sample(1:nrow(music_dataset)), ]
# Visualizzazione istogrammi per ogni feature
par(mfrow=c(3,3))
hist(music_dataset$popularity, freq=F, main="Istogramma popularity", xlab="populariy", col = "green")
hist(music_dataset$acousticness, freq=F, main="Istogramma acousticness", xlab="acousticness", col = "red")
hist(music_dataset$danceability, freq=F, main="Istogramma danceability", xlab="danceability", col = "white")
hist(music_dataset$duration_ms, freq=F, main="Istogramma duration_ms", xlab="duration_ms", col = "yellow")
hist(music_dataset$energy, freq=F, main="Istogramma energy", xlab="energy", col = "orange")
hist(music_dataset$instrumentalness, freq=F, main="Istogramma instrumentalness", xlab="instrumentalness", col = "blue")
hist(music_dataset$key, freq=F, main="Istogramma key", xlab="key", col = "purple")
hist(music_dataset$liveness, freq=F, main="Istogramma liveness", xlab="liveness", col = "cyan")
hist(music_dataset$loudness, freq=F, main="Istogramma loudness", xlab="loudness", col = "gray")
par(mfrow=c(2,2))
hist(music_dataset$mode, freq=F, main="Istogramma mode", xlab="mode", col = "green")
hist(music_dataset$speechiness, freq=F, main="Istogramma speechiness", xlab="speechiness", col = "red")
hist(music_dataset$tempo, freq=F, main="Istogramma tempo", xlab="tempo", col = "blue")
hist(music_dataset$valence, freq=F, main="Istogramma valence", xlab="valence", col = "orange")
glimpse(music_dataset)
# TESTING:
#music_dataset <- music_dataset[, c("danceability","acousticness","instrumentalness","energy","loudness","key","liveness","music_genre")]
# Split del dataset in:
# training_set: 65%
# testing_set: 25%
# validation_set: 10%
train_prop <- 0.65
test_prop <- 0.25
vald_prop = 1 - train_prop - test_prop
indices <- sample(x = rep.int(x = c(0, 1, 2), times = round(nrow(music_dataset) * c(vald_prop, train_prop, test_prop))))
training_set <- music_dataset[indices == 1,]
testing_set <- music_dataset[indices == 2,]
validation_set <- music_dataset[indices == 0,]
dim(music_dataset)
dim(training_set)
dim(testing_set)
dim(validation_set)
## K-Fold Cross Validation method
# Setting a seed (reproduce results)
# K = 10
set.seed(123)
trctrl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre~., data = data, method = "randomForest", trControl=trctrl, tuneLength = 0)
randomForest_fit
## K-Fold Cross Validation method
# Setting a seed (reproduce results)
# K = 10
set.seed(123)
trctrl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre~., data = music_dataset, method = "randomForest", trControl=trctrl, tuneLength = 0)
randomForest_fit
## K-Fold Cross Validation method
# Setting a seed (reproduce results)
# K = 10
set.seed(123)
trctrl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre~., data = music_dataset, method = "rf", trControl=trctrl, tuneLength = 0)
randomForest_fit
## K-Fold Cross Validation method
# Setting a seed (reproduce results)
# K = 10
set.seed(2)
trctrl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre~., data = music_dataset, method = "rf", trControl=trctrl, tuneLength = 0)
randomForest_fit
pred <- randomForest_fit$pred
pred$equal <- ifelse(pred$pred == pred$obs, 1,0)
eachfold <- pred %>%
group_by(Resample) %>%
summarise_at(vars(equal),
list(Accuracy = mean))
eachfold
trctrl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre~., data = music_dataset, method = "rf", trControl=trctrl, tuneLength = 0)
randomForest_fit
trctrl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre~., data = music_dataset, method = "rf", trControl=trctrl, tuneLength = 0)
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre~., data = music_dataset, method = "rf", trControl=trainControl, tuneLength = 0)
randomForest_fit
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(factor(music_genre)~., data = music_dataset, method = "rf", trControl=trainControl, tuneLength = 0)
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre~., data = music_dataset, method = "rf", trControl=trainControl, tuneLength = 0, importance=T)
randomForest_fit
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre~., data = music_dataset, method = "rf", trControl=trainControl, tuneLength = 0, importance=T)
class(music_genre)
class(music_dataset$music_genre)
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_dataset$music_genre~., data = music_dataset, method = "rf", trControl=trainControl, tuneLength = 0, importance=T)
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_dataset$music_genre~., data = training_set, method = "rf", trControl=trainControl, tuneLength = 0, importance=T)
randomForest_fit
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_dataset,music_dataset$music_genre, method = "rf", trControl=trainControl, tuneLength = 0, importance=T)
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre ~ ., data=music_dataset, method = "rf", trControl=trainControl, tuneLength = 0, importance=T)
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre ~ ., data=music_dataset, method = "nv", trControl=trainControl, tuneLength = 0, importance=T)
randomForest_fit
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre ~ ., data=music_dataset, method = "knn3", trControl=trainControl, tuneLength = 0, importance=T)
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre ~ ., data=music_dataset, method = "rf", trControl=trainControl, tuneLength = 0, importance=T)
randomForest_fit
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre ~ ., data=music_dataset, method = "svm", trControl=trainControl, tuneLength = 0, importance=T)
randomForest_fit
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre ~ ., data=music_dataset, method = "svmlinear", trControl=trainControl, tuneLength = 0, importance=T)
randomForest_fit
set.seed(123)
trainControl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
randomForest_fit <- train(music_genre ~ ., data=music_dataset, method = "svmLinear", trControl=trainControl, tuneLength = 0, importance=T)
randomForest_fit
pred <- randomForest_fit$pred
pred$equal <- ifelse(pred$pred == pred$obs, 1,0)
eachfold <- pred %>%
group_by(Resample) %>%
summarise_at(vars(equal),
list(Accuracy = mean))
eachfold
# PCA sul traninig_set
pca_set = training_set[,-14]
res.pca <- PCA(pca_set, scale.unit = TRUE, ncp = 5, graph = FALSE)
# autovalori
eig.val <- get_eigenvalue(res.pca)
eig.val
# var
var <- get_pca_var(res.pca)
var
dev.off()
# Corr circle
fviz_pca_var(res.pca, col.var = "black")
# Scree plot
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
# Correlation plot su var cos2
corrplot(var$cos2, is.corr=FALSE)
# Correlation plot su var contrib
corrplot(var$contrib, is.corr=FALSE)
# Contributions of variables to PC1 and PC2
fviz_pca_ind(res.pca,
geom.ind = "point", # show points only (nbut not "text")
col.ind = training_set$music_genre, # color by groups
palette = c("#ff0000", "#ff8000", "#ffff00","#80ff00","#00ff00","#00ff80","#00ffff","#00ffff","#0000ff","#8000ff","#ff00ff","#ff0080"),
addEllipses = TRUE, # Concentration ellipses
legend.title = "Groups",
title = "Contrb by each music genre"
)
# Biplot identificazione top features (PC1)
top_features_pc1 <- fviz_pca_biplot(res.pca, select.ind = list(contrib = 5),
select.var = list(contrib = 5))
top_features_pc1
par(mfrow=c(2,3))
plot(training_set$danceability, main="Danzabilità", col="green")
plot(training_set$acousticness, main="Acustica", col="red")
plot(training_set$instrumentalness, main="Strumentalità", col="blue")
plot(training_set$energy, main="Energia", col="orange")
plot(training_set$loudness, main="Rumorosità", col="black")
## K-Means
kmeans.re <- kmeans(music_dataset[-14], centers = 10, nstart = 20)
kmeans.re
kmeans.re$cluster
# Confusion Matrix
cm_kmeans <- table(music_dataset$music_genre, kmeans.re$cluster)
cm_kmeans
# Confusion Matrix
cm_kmeans.confusionMatrix = confusionMatrix(kmeans.re$cluster, testing_set$music_genre, mode = "everything")
cm_kmeans.confusionMatrix$overall[1]
cm_kmeans.table = table(music_dataset$music_genre, kmeans.re$cluster)
cm_kmeans.table
accuracy.cm_kmeans <- sum(diag(cm_kmeans.table))/sum(cm_kmeans.table)
print(accuracy.cm_kmeans)
# svm.confusionMatrix
svm.confusionMatrix = confusionMatrix(svm.pred, testing_set$music_genre, mode = "everything")
print(svm.confusionMatrix)
svm.confusionMatrix$overall[1]
kmeans.re$centers
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
kmeans.re$centers[, lables]
fviz_cluster(kmeans.re$centers)
fviz_cluster(kmeans.re)
fviz_cluster(kmeans.re$cluster)
fviz_cluster(kmeans.re)
fviz_cluster(kmeans.re, data =music_dataset)
fviz_cluster(kmeans.re, data =music_dataset[-14])
fviz_cluster(kmeans.re, data =music_dataset[-14], repel = TRUE)
kmeans.re$betweenss/kmeans.re$totss*100
print(kmeans.re$betweenss/kmeans.re$totss*100)
# Confusion Matrix
cm_kmeans.table = table(music_dataset$music_genre, kmeans.re$cluster)
cm_kmeans.table
accuracy.cm_kmeans <- sum(diag(cm_kmeans.table))/sum(cm_kmeans.table)
print(accuracy.cm_kmeans)
## Neural networks
training_set_nn <- data.frame(training_set$danceability, training_set$acousticness, training_set$instrumentalness, training_set$energy, training_set$loudness, training_set$music_genre)
names(training_set_nn) <- c('danceability','acousticness','instrumentalness','energy','loudness','music_genre')
head(training_set_nn)
network = neuralnet(music_genre~ danceability + acousticness + instrumentalness + energy + loudness, data = training_set_nn, hidden=3)
network$startweights
network$weights
plot(network)
train_prop <- 0.65
test_prop <- 0.25
vald_prop = 1 - train_prop - test_prop
indices <- sample(x = rep.int(x = c(0, 1, 2), times = round(nrow(music_dataset) * c(vald_prop, train_prop, test_prop))))
training_set <- music_dataset[indices == 1,]
testing_set <- music_dataset[indices == 2,]
validation_set <- music_dataset[indices == 0,]
dim(music_dataset)
dim(training_set)
dim(testing_set)
dim(validation_set)
training_set_nn <- data.frame(training_set$danceability, training_set$acousticness, training_set$instrumentalness, training_set$energy, training_set$loudness, training_set$key, training_set$liveness, training_set$music_genre)
names(training_set_nn) <- c('danceability','acousticness','instrumentalness','energy','loudness','key','liveness','music_genre')
head(training_set_nn)
library(MLmetrics)
library(FactoMineR)
library(factoextra)
library(randomForest)
library(C50)
library(caret)
library(e1071)
library(dplyr)
library(corrplot)
library(neuralnet)
library(tidyr)
library(magrittr)
library(tidyverse)
# Caricamento dataset da file csv
music_dataset <- read.csv("music_genre.csv", header = TRUE)
# Dimensione dataset
dim(music_dataset)
# Stampa di n righe random del dataset
sample_n(music_dataset, 5)
summary(music_dataset)
# Verifica e rimozione di eventuali righe duplicate e con valori NA nelle colonne
music_dataset <- na.omit(music_dataset)
music_dataset <- music_dataset[complete.cases(music_dataset),]
dim(music_dataset[rowSums(is.na(music_dataset)) > 0, ])
music_dataset %>% drop_na()
# Reset dell'index dopo la cancellazione di alcune righe
row.names(music_dataset) <- NULL
dim(music_dataset)
# Labels del genere musicale e distrubuzione dei generi musicali nel df
lables <- unique(music_dataset$music_genre)
table(music_dataset$music_genre)
# Rimozione delle colonne rappresentanti feature inutili alla classificazione con i modelli
# quindi, principalmente si eliminano i caratteri qualitativi che non saranno trasformati in factors
# in particolare si eliminano le features che non influenzerebbero la classificazione
music_dataset <- within(music_dataset, rm('instance_id', 'track_name', 'obtained_date', 'index', 'artist_name'))
dim(music_dataset)
sample_n(music_dataset, 5)
# Codifica delle colonne con valori qualitativi attraverso factors(x, levels)
# Per utilizzare nei modelli le colonne "key" e "mode" si codificano mappandone i valori
# al fine di renderli valori numerici
# "mode" - codifica in valori pari a 1 o 2 (majior o minor)
# "key" - codifica fino a 12 valori (suoni note musicali)
encode_ordinal <- function(x, order = unique(x)) {
x <- as.numeric(factor(x, levels = order, exclude = NULL))
x
}
music_dataset[["key"]] <- encode_ordinal(music_dataset[["key"]])
head(music_dataset)
music_dataset[["mode"]] <- encode_ordinal(music_dataset[["mode"]])
head(music_dataset)
music_dataset$tempo <- as.double(music_dataset$tempo)
head(music_dataset)
# Eliminazione delle righe con feature: duration_ms pari a -1
# quindi dei brani con durata non presente nel dataset
music_dataset <- filter(music_dataset, duration_ms != -1)
# Trasformazione delle lables da type: chr a type: factor
music_dataset$music_genre = as.factor(music_dataset$music_genre)
str(music_dataset)
dim(music_dataset)
# Verifica e rimozione dei valori NA dopo la codifica delle features "key" e "mode"
music_dataset <- na.omit(music_dataset)
music_dataset <- music_dataset[complete.cases(music_dataset),]
dim(music_dataset[rowSums(is.na(music_dataset)) > 0, ])
music_dataset %>% drop_na()
# Normalizzazione del dataset per tutte le features con dominio numerico
process <- preProcess(as.data.frame(music_dataset), method=c("center", "scale"))
music_dataset <- predict(process, as.data.frame(music_dataset))
glimpse(music_dataset)
summary(music_dataset)
table(music_dataset$music_genre)
# Plotting ed eliminazione degli outliers
# plotting per ogni colonna
for (i in colnames(music_dataset)){
if(is.numeric(music_dataset[[i]])){
boxplot(music_dataset[[i]],
main = paste("Boxplot", i),
xlab = "values",
ylab =  i,
col = "cyan",
border = "blue",
horizontal = TRUE,
notch = FALSE
)}}
head(music_dataset)
z_scores = as.data.frame(sapply(music_dataset, function(music_dataset) (abs(music_dataset-mean(music_dataset))/sd(music_dataset))))
no_outliers = z_scores[!rowSums(z_scores>3), ]
head(no_outliers)
# Shuffle del dataset
music_dataset = music_dataset[sample(1:nrow(music_dataset)), ]
# Visualizzazione istogrammi per ogni feature
par(mfrow=c(3,3))
hist(music_dataset$popularity, freq=F, main="Istogramma popularity", xlab="populariy", col = "green")
hist(music_dataset$acousticness, freq=F, main="Istogramma acousticness", xlab="acousticness", col = "red")
hist(music_dataset$danceability, freq=F, main="Istogramma danceability", xlab="danceability", col = "white")
hist(music_dataset$duration_ms, freq=F, main="Istogramma duration_ms", xlab="duration_ms", col = "yellow")
hist(music_dataset$energy, freq=F, main="Istogramma energy", xlab="energy", col = "orange")
hist(music_dataset$instrumentalness, freq=F, main="Istogramma instrumentalness", xlab="instrumentalness", col = "blue")
hist(music_dataset$key, freq=F, main="Istogramma key", xlab="key", col = "purple")
hist(music_dataset$liveness, freq=F, main="Istogramma liveness", xlab="liveness", col = "cyan")
hist(music_dataset$loudness, freq=F, main="Istogramma loudness", xlab="loudness", col = "gray")
par(mfrow=c(2,2))
hist(music_dataset$mode, freq=F, main="Istogramma mode", xlab="mode", col = "green")
hist(music_dataset$speechiness, freq=F, main="Istogramma speechiness", xlab="speechiness", col = "red")
hist(music_dataset$tempo, freq=F, main="Istogramma tempo", xlab="tempo", col = "blue")
hist(music_dataset$valence, freq=F, main="Istogramma valence", xlab="valence", col = "orange")
glimpse(music_dataset)
# TESTING:
#music_dataset <- music_dataset[, c("danceability","acousticness","instrumentalness","energy","loudness","key","liveness","music_genre")]
# Split del dataset in:
# training_set: 65%
# testing_set: 25%
# validation_set: 10%
train_prop <- 0.65
test_prop <- 0.25
vald_prop = 1 - train_prop - test_prop
indices <- sample(x = rep.int(x = c(0, 1, 2), times = round(nrow(music_dataset) * c(vald_prop, train_prop, test_prop))))
training_set <- music_dataset[indices == 1,]
testing_set <- music_dataset[indices == 2,]
validation_set <- music_dataset[indices == 0,]
dim(music_dataset)
dim(training_set)
dim(testing_set)
dim(validation_set)
# PCA sul traninig_set
pca_set = training_set[,-14]
res.pca <- PCA(pca_set, scale.unit = TRUE, ncp = 5, graph = FALSE)
# autovalori
eig.val <- get_eigenvalue(res.pca)
eig.val
# var
var <- get_pca_var(res.pca)
var
dev.off()
# Corr circle
fviz_pca_var(res.pca, col.var = "black")
# Scree plot
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
# Correlation plot su var cos2
corrplot(var$cos2, is.corr=FALSE)
# Correlation plot su var contrib
corrplot(var$contrib, is.corr=FALSE)
# Contributions of variables to PC1 and PC2
fviz_pca_ind(res.pca,
geom.ind = "point", # show points only (nbut not "text")
col.ind = training_set$music_genre, # color by groups
palette = c("#ff0000", "#ff8000", "#ffff00","#80ff00","#00ff00","#00ff80","#00ffff","#00ffff","#0000ff","#8000ff","#ff00ff","#ff0080"),
addEllipses = TRUE, # Concentration ellipses
legend.title = "Groups",
title = "Contrb by each music genre"
)
# Biplot identificazione top features (PC1)
top_features_pc1 <- fviz_pca_biplot(res.pca, select.ind = list(contrib = 5),
select.var = list(contrib = 5))
top_features_pc1
par(mfrow=c(2,3))
plot(training_set$danceability, main="Danzabilità", col="green")
plot(training_set$acousticness, main="Acustica", col="red")
plot(training_set$instrumentalness, main="Strumentalità", col="blue")
plot(training_set$energy, main="Energia", col="orange")
plot(training_set$loudness, main="Rumorosità", col="black")
## Neural network
training_set_nn <- data.frame(training_set$danceability, training_set$acousticness, training_set$instrumentalness, training_set$energy, training_set$loudness, training_set$key, training_set$liveness, training_set$music_genre)
names(training_set_nn) <- c('danceability','acousticness','instrumentalness','energy','loudness','key','liveness','music_genre')
head(training_set_nn)
network = neuralnet(music_genre~ danceability + acousticness + instrumentalness + energy + loudness + key + liveness, data = training_set_nn, hidden=3)
network$startweights
network$weights
plot(network)
network$startweights
network$weights
plot(network)
network$weights
plot(network)
#plots covariate
par(mfrow=c(2,3))
gwplot(network,selected.covariate="danceability")
gwplot(network,selected.covariate="acousticness")
gwplot(network,selected.covariate="instrumentalness")
gwplot(network,selected.covariate="energy")
gwplot(network,selected.covariate="loudness")
training_set_nn <- data.frame(training_set$danceability, training_set$acousticness, training_set$instrumentalness, training_set$energy, training_set$loudness, training_set$key, training_set$liveness, training_set$music_genre)
names(training_set_nn) <- c('danceability','acousticness','instrumentalness','energy','loudness','key','liveness','music_genre')
head(training_set_nn)
head(training_set_nn)
plot(training_set$danceability[1:1000], main="Danzabilità", col="green")
plot(training_set$danceability[1:10000], main="Danzabilità", col="green")
plot(training_set$danceability[1:5000], main="Danzabilità", col="green")
plot(training_set$danceability[1:2000], main="Danzabilità", col="green")
par(mfrow=c(2,3))
plot(training_set$danceability[1:2000], main="Danzabilità", col="green")
plot(training_set$acousticness[1:2000], main="Acustica", col="red")
plot(training_set$instrumentalness[1:2000], main="Strumentalità", col="blue")
plot(training_set$energy[1:2000], main="Energia", col="orange")
plot(training_set$loudness[1:2000], main="Rumorosità", col="black")
