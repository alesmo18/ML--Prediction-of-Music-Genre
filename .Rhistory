install.packages("Rcpp")
music = read.csv("music_genre.csv", header = TRUE)
head(music)
dim(music)
anyDuplicated(music)
duplicated = duplicated(music)
music[duplicated, ]
music[9999:10006, ]
music = music[-c(10001, 10002, 10003, 10004, 10005), ]
music[9999:10009, ]
dim(music)
length(unique(music$instance_id))
length(unique(music$artist_name))
unique(music$key)
unique(music$mode)
unique(music$obtained_date)
unique(music$music_genre)
table(music$music_genre)
row.names(music) <- NULL
music[9999:10009, ]
music = within(music, rm('instance_id', 'track_name', 'obtained_date', 'index', 'artist_name'))
head(music)
encode_ordinal <- function(x, order = unique(x)) {
x <- as.numeric(factor(x, levels = order, exclude = NULL))
x
}
music[["key"]] <- encode_ordinal(music[["key"]])
head(music)
music[["mode"]] <- encode_ordinal(music[["mode"]])
head(music)
music$tempo <- as.double(music$tempo)
head(music)
music_features = music[,-14]
music_labels = music[,14]
head(music_features)
music$music_genre = as.factor(music$music_genre)
music = music[complete.cases(music),]
dim(music[rowSums(is.na(music)) > 0, ])
music_shuffled= music[sample(1:nrow(music)), ]
head(music_shuffled)
dim(music_shuffled)
training_set = music_shuffled[1:24761,]
dim(training_set)
pca_set = training_set[,-14]
head(training_set)
test_set = music_shuffled[24762:36016,]
dim(test_set)
head(test_set)
validation_set = music_shuffled[36017:nrow(music),]
dim(validation_set)
head(validation_set)
res.pca <- PCA(pca_set, scale.unit = TRUE, ncp = 5, graph = TRUE)
install.packages("RcppArmadillo")
install.packages(c("FactoMineR", "factoextra"))
install.packages("randomForest")
library("FactoMineR")
library("factoextra")
library(randomForest)
install.packages("C50")
library(C50)
install.packages("caret")
library(caret)
install.packages('MLmetrics')
library('MLmetrics')
music = read.csv("music_genre.csv", header = TRUE)
head(music)
dim(music)
anyDuplicated(music)
duplicated = duplicated(music)
music[duplicated, ]
music[9999:10006, ]
music = music[-c(10001, 10002, 10003, 10004, 10005), ]
music[9999:10009, ]
dim(music)
length(unique(music$instance_id))
length(unique(music$artist_name))
unique(music$key)
unique(music$mode)
unique(music$obtained_date)
unique(music$music_genre)
table(music$music_genre)
row.names(music) <- NULL
music[9999:10009, ]
music = within(music, rm('instance_id', 'track_name', 'obtained_date', 'index', 'artist_name'))
head(music)
encode_ordinal <- function(x, order = unique(x)) {
x <- as.numeric(factor(x, levels = order, exclude = NULL))
x
}
music[["key"]] <- encode_ordinal(music[["key"]])
head(music)
music[["mode"]] <- encode_ordinal(music[["mode"]])
head(music)
music$tempo <- as.double(music$tempo)
head(music)
music_features = music[,-14]
music_labels = music[,14]
head(music_features)
music$music_genre = as.factor(music$music_genre)
music = music[complete.cases(music),]
dim(music[rowSums(is.na(music)) > 0, ])
music_shuffled= music[sample(1:nrow(music)), ]
head(music_shuffled)
dim(music_shuffled)
training_set = music_shuffled[1:24761,]
dim(training_set)
pca_set = training_set[,-14]
head(training_set)
test_set = music_shuffled[24762:36016,]
dim(test_set)
head(test_set)
validation_set = music_shuffled[36017:nrow(music),]
dim(validation_set)
head(validation_set)
res.pca <- PCA(pca_set, scale.unit = TRUE, ncp = 5, graph = TRUE)
eig.val <- get_eigenvalue(res.pca)
eig.val
#fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
#var <- get_pca_var(res.pca)
#head(var$coord, 13)
top_features <- fviz_pca_biplot(res.pca, select.ind = list(contrib = 5),
select.var = list(contrib = 5),
ggtheme = theme_minimal())
top_features
training_set[0,]
head(training_set)
svm.model = svm(music_genre ~ ., data=training_set, kernel='radial', cost=1)
#install.packages(c("FactoMineR", "factoextra"))
#install.packages("randomForest")
library("FactoMineR")
library("factoextra")
library(randomForest)
#install.packages("C50")
library(C50)
#install.packages("caret")
library(caret)
#install.packages('MLmetrics')
library('MLmetrics')
library(e1071)
music = read.csv("music_genre.csv", header = TRUE)
head(music)
dim(music)
anyDuplicated(music)
duplicated = duplicated(music)
music[duplicated, ]
music[9999:10006, ]
music = music[-c(10001, 10002, 10003, 10004, 10005), ]
music[9999:10009, ]
dim(music)
length(unique(music$instance_id))
length(unique(music$artist_name))
unique(music$key)
unique(music$mode)
unique(music$obtained_date)
unique(music$music_genre)
table(music$music_genre)
row.names(music) <- NULL
music[9999:10009, ]
music = within(music, rm('instance_id', 'track_name', 'obtained_date', 'index', 'artist_name'))
head(music)
encode_ordinal <- function(x, order = unique(x)) {
x <- as.numeric(factor(x, levels = order, exclude = NULL))
x
}
music[["key"]] <- encode_ordinal(music[["key"]])
head(music)
music[["mode"]] <- encode_ordinal(music[["mode"]])
head(music)
music$tempo <- as.double(music$tempo)
head(music)
music_features = music[,-14]
music_labels = music[,14]
head(music_features)
music$music_genre = as.factor(music$music_genre)
music = music[complete.cases(music),]
dim(music[rowSums(is.na(music)) > 0, ])
music_shuffled= music[sample(1:nrow(music)), ]
head(music_shuffled)
dim(music_shuffled)
training_set = music_shuffled[1:24761,]
dim(training_set)
pca_set = training_set[,-14]
head(training_set)
test_set = music_shuffled[24762:36016,]
dim(test_set)
head(test_set)
validation_set = music_shuffled[36017:nrow(music),]
dim(validation_set)
head(validation_set)
res.pca <- PCA(pca_set, scale.unit = TRUE, ncp = 5, graph = TRUE)
eig.val <- get_eigenvalue(res.pca)
eig.val
#fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
#var <- get_pca_var(res.pca)
#head(var$coord, 13)
top_features <- fviz_pca_biplot(res.pca, select.ind = list(contrib = 5),
select.var = list(contrib = 5),
ggtheme = theme_minimal())
top_features
training_set[0,]
head(training_set)
svm.model = svm(music_genre ~ ., data=training_set, kernel='radial', cost=1)
summary(svm.model)
randomForest.model <- randomForest(music_genre ~ ., data = training_set, importance = TRUE)
summary(randomForest.model)
svm.pred = predict(svm.model, test_set)
randomForest.pred = predict(randomForest.model, test_set)
length(randomForest.pred)
length(test_set$music_genre)
randomForest.table = table(randomForest.pred, test_set$music_genre)
randomForest.table
svm.table=table(svm.pred, test_set$music_genre)
svm.table
svm.confusionMatrix = confusionMatrix(svm.pred, test_set$music_genre, mode = "everything")
#svm.confusionMatrix
randomForest.confusionMatrix = confusionMatrix(randomForest.pred, test_set$music_genre, mode = "everything")
#randomForest.confusionMatrix
ind = sample(2, nrow(iris), replace = TRUE, prob=c(0.7, 0.3))
ind
testset = iris[ind == 2,]
head(testset)
trainset = iris[ind == 1,]
head(trainset)
library(MLmetrics)
library(FactoMineR)
library(factoextra)
library(randomForest)
library(C50)
library(caret)
library(e1071)
library(dplyr)
library(corrplot)
library(neuralnet)
library(tidyr)
# Caricamento dataset da file csv
music_dataset <- read.csv("music_genre.csv", header = TRUE)
# Dimensione dataset
dim(music_dataset)
# Stampa di n righe random del dataset
sample_n(music_dataset, 5)
summary(music_dataset)
# Verifica e rimozione di eventuali righe duplicate e con valori NA nelle colonne
music_dataset <- na.omit(music_dataset)
music_dataset <- music_dataset[complete.cases(music_dataset),]
dim(music_dataset[rowSums(is.na(music_dataset)) > 0, ])
music_dataset %>% drop_na()
# Reset dell'index dopo la cancellazione di alcune righe
row.names(music_dataset) <- NULL
dim(music_dataset)
# Labels del genere musicale e distrubuzione dei generi musicali nel df
lables <- unique(music_dataset$music_genre)
table(music_dataset$music_genre)
# Rimozione delle colonne rappresentanti feature inutili alla classificazione con i modelli
# quindi, principalmente si eliminano i caratteri qualitativi che non saranno trasformati in factors
music_dataset <- within(music_dataset, rm('instance_id', 'track_name', 'obtained_date', 'index', 'artist_name'))
dim(music_dataset)
sample_n(music_dataset, 5)
# Codifica delle colonne con valori qualitativi attraverso factors(x, levels)
# Per utilizzare nei modelli le colonne "key" e "mode" si codificano mappandone i valori
# al fine di renderli valori numerici
# "mode" - codifica in valori pari a 1 o 2 (majior o minor)
# "key" - codifica fino a 12 valori (suoni note musicali)
encode_ordinal <- function(x, order = unique(x)) {
x <- as.numeric(factor(x, levels = order, exclude = NULL))
x
}
music_dataset[["key"]] <- encode_ordinal(music_dataset[["key"]])
head(music_dataset)
music_dataset[["mode"]] <- encode_ordinal(music_dataset[["mode"]])
head(music_dataset)
music_dataset$tempo <- as.double(music_dataset$tempo)
head(music_dataset)
# Trasformazione delle lables da type: chr a type: factor
music_dataset$music_genre = as.factor(music_dataset$music_genre)
str(music_dataset)
dim(music_dataset)
# Verifica e rimozione dei valori NA dopo la codifica delle features "key" e "mode"
music_dataset <- na.omit(music_dataset)
music_dataset <- music_dataset[complete.cases(music_dataset),]
dim(music_dataset[rowSums(is.na(music_dataset)) > 0, ])
music_dataset %>% drop_na()
setwd("~/ML-Progetto-MusicGenre")
# Caricamento dataset da file csv
music_dataset <- read.csv("music_genre.csv", header = TRUE)
# Dimensione dataset
dim(music_dataset)
# Stampa di n righe random del dataset
sample_n(music_dataset, 5)
summary(music_dataset)
# Verifica e rimozione di eventuali righe duplicate e con valori NA nelle colonne
music_dataset <- na.omit(music_dataset)
music_dataset <- music_dataset[complete.cases(music_dataset),]
dim(music_dataset[rowSums(is.na(music_dataset)) > 0, ])
music_dataset %>% drop_na()
# Reset dell'index dopo la cancellazione di alcune righe
row.names(music_dataset) <- NULL
dim(music_dataset)
# Labels del genere musicale e distrubuzione dei generi musicali nel df
lables <- unique(music_dataset$music_genre)
table(music_dataset$music_genre)
# Rimozione delle colonne rappresentanti feature inutili alla classificazione con i modelli
# quindi, principalmente si eliminano i caratteri qualitativi che non saranno trasformati in factors
music_dataset <- within(music_dataset, rm('instance_id', 'track_name', 'obtained_date', 'index', 'artist_name'))
dim(music_dataset)
sample_n(music_dataset, 5)
# Codifica delle colonne con valori qualitativi attraverso factors(x, levels)
# Per utilizzare nei modelli le colonne "key" e "mode" si codificano mappandone i valori
# al fine di renderli valori numerici
# "mode" - codifica in valori pari a 1 o 2 (majior o minor)
# "key" - codifica fino a 12 valori (suoni note musicali)
encode_ordinal <- function(x, order = unique(x)) {
x <- as.numeric(factor(x, levels = order, exclude = NULL))
x
}
music_dataset[["key"]] <- encode_ordinal(music_dataset[["key"]])
head(music_dataset)
music_dataset[["mode"]] <- encode_ordinal(music_dataset[["mode"]])
head(music_dataset)
music_dataset$tempo <- as.double(music_dataset$tempo)
head(music_dataset)
# Trasformazione delle lables da type: chr a type: factor
music_dataset$music_genre = as.factor(music_dataset$music_genre)
str(music_dataset)
dim(music_dataset)
# Verifica e rimozione dei valori NA dopo la codifica delle features "key" e "mode"
music_dataset <- na.omit(music_dataset)
music_dataset <- music_dataset[complete.cases(music_dataset),]
dim(music_dataset[rowSums(is.na(music_dataset)) > 0, ])
music_dataset %>% drop_na()
# plotting per ogni colonna
for (i in colnames(music_dataset)){
boxplot(music_dataset[[i]],
main = paste("Boxplot", i),
xlab = "values",
ylab =  i,
col = "cyan",
border = "blue",
horizontal = TRUE,
notch = FALSE
)}
cols <- colnames(music_dataset)
cols <- cols[-14]
for(i in cols){
#find Q1, Q3, and interquartile range for values in column A
Q1 <- quantile(music_dataset$i, .25)
Q3 <- quantile(music_dataset$i, .75)
IQR <- IQR(music_dataset$i)
#only keep rows in dataframe that have values within 1.5*IQR of Q1 and Q3
no_outliers <- subset(music_dataset, music_dataset$i> (Q1 - 1.5*IQR) & music_dataset$i< (Q3 + 1.5*IQR))
#view row and column count of new data frame
dim(no_outliers)
}
for (i in colnames(no_outliers)){
boxplot(no_outliers[[i]],
main = paste("Boxplot", i),
xlab = "values",
ylab =  i,
col = "cyan",
border = "blue",
horizontal = TRUE,
notch = FALSE
)}
music_dataset = no_outliers
# Shuffle del dataset
music_dataset = music_dataset[sample(1:nrow(music_dataset)), ]
# Normalizzazione del dataset per tutte le features con dominio numerico
process <- preProcess(as.data.frame(music_dataset), method=c("range"))
music_dataset <- predict(process, as.data.frame(music_dataset))
# Visualizzazione istogrammi per ogni feature
par(mfrow=c(3,3))
hist(music_dataset$popularity, freq=F, main="Istogramma popularity", xlab="populariy", col = "green")
hist(music_dataset$acousticness, freq=F, main="Istogramma acousticness", xlab="acousticness", col = "red")
hist(music_dataset$danceability, freq=F, main="Istogramma danceability", xlab="danceability", col = "white")
hist(music_dataset$duration_ms, freq=F, main="Istogramma duration_ms", xlab="duration_ms", col = "yellow")
hist(music_dataset$energy, freq=F, main="Istogramma energy", xlab="energy", col = "orange")
hist(music_dataset$instrumentalness, freq=F, main="Istogramma instrumentalness", xlab="instrumentalness", col = "blue")
hist(music_dataset$key, freq=F, main="Istogramma key", xlab="key", col = "purple")
hist(music_dataset$liveness, freq=F, main="Istogramma liveness", xlab="liveness", col = "cyan")
hist(music_dataset$loudness, freq=F, main="Istogramma loudness", xlab="loudness", col = "gray")
par(mfrow=c(2,2))
hist(music_dataset$mode, freq=F, main="Istogramma mode", xlab="mode", col = "green")
hist(music_dataset$speechiness, freq=F, main="Istogramma speechiness", xlab="speechiness", col = "red")
hist(music_dataset$tempo, freq=F, main="Istogramma tempo", xlab="tempo", col = "blue")
hist(music_dataset$valence, freq=F, main="Istogramma valence", xlab="valence", col = "orange")
# Split del dataset in:
# training_set: 65%
# testing_set: 25%
# validation_set: 10%
train_prop <- 0.65
test_prop <- 0.25
vald_prop = 1 - train_prop - test_prop
indices <- sample(x = rep.int(x = c(0, 1, 2), times = round(nrow(music_dataset) * c(vald_prop, train_prop, test_prop))))
training_set <- music_dataset[indices == 1,]
testing_set <- music_dataset[indices == 2,]
validation_set <- music_dataset[indices == 0,]
dim(music_dataset)
dim(training_set)
dim(testing_set)
dim(validation_set)
# PCA sul traninig_set
pca_set = training_set[,-14]
res.pca <- PCA(pca_set, scale.unit = TRUE, ncp = 5, graph = TRUE)
# autovalori
eig.val <- get_eigenvalue(res.pca)
eig.val
# var
var <- get_pca_var(res.pca)
var
# Scree plot
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
# Correlation plot su var cos2
corrplot(var$cos2, is.corr=FALSE)
# Correlation plot su var contrib
corrplot(var$contrib, is.corr=FALSE)
# Contributions of variables to PC1 and PC2
fviz_pca_ind(res.pca,
geom.ind = "point", # show points only (nbut not "text")
col.ind = training_set$music_genre, # color by groups
palette = c("#ff0000", "#ff8000", "#ffff00","#80ff00","#00ff00","#00ff80","#00ffff","#00ffff","#0000ff","#8000ff","#ff00ff","#ff0080"),
addEllipses = TRUE, # Concentration ellipses
legend.title = "Groups",
title = "Contrb by each music genre"
)
# Biplot identificazione top features
top_features <- fviz_pca_biplot(res.pca, select.ind = list(contrib = 5),
select.var = list(contrib = 5))
top_features
par(mfrow=c(2,3))
plot(training_set$danceability, main="Danzabilità", col="green")
plot(training_set$acousticness, main="Acustica", col="red")
plot(training_set$instrumentalness, main="Strumentalità", col="blue")
plot(training_set$energy, main="Energia", col="orange")
plot(training_set$loudness, main="Rumorosità", col="black")
## Primo modello : SVM
svm.model = svm(music_genre ~ ., data=training_set, kernel='radial', cost=1)
summary(svm.model)
## Secondo modello: Random Forest
randomForest.model = randomForest(music_genre ~ ., data=training_set, importance = TRUE)
summary(randomForest.model)
## Predictions
svm.pred = predict(svm.model, testing_set)
randomForest.pred = predict(randomForest.model, testing_set)
length(randomForest.pred)
length(testing_set$music_genre)
randomForest.table = table(randomForest.pred, testing_set$music_genre)
randomForest.table
accuracy.RF <- sum(diag(randomForest.table))/sum(randomForest.table)
print(accuracy.RF)
svm.table=table(svm.pred, testing_set$music_genre)
svm.table
accuracy.SVM <- sum(diag(svm.table))/sum(svm.table)
print(accuracy.SVM)
#  K-Fold Cross-Validation
# svm.confusionMatrix
svm.confusionMatrix = confusionMatrix(svm.pred, testing_set$music_genre, mode = "everything")
print(svm.confusionMatrix)
svm.confusionMatrix$overall[1]
# randomForest.confusionMatrix
randomForest.confusionMatrix = confusionMatrix(randomForest.pred, testing_set$music_genre, mode = "everything")
randomForest.confusionMatrix$overall[1]
# Caricamento dataset da file csv
music_dataset <- read.csv("music_genre.csv", header = TRUE)
# Dimensione dataset
dim(music_dataset)
# Stampa di n righe random del dataset
sample_n(music_dataset, 5)
summary(music_dataset)
# Verifica e rimozione di eventuali righe duplicate e con valori NA nelle colonne
music_dataset <- na.omit(music_dataset)
music_dataset <- music_dataset[complete.cases(music_dataset),]
dim(music_dataset[rowSums(is.na(music_dataset)) > 0, ])
music_dataset %>% drop_na()
# Reset dell'index dopo la cancellazione di alcune righe
row.names(music_dataset) <- NULL
dim(music_dataset)
# Labels del genere musicale e distrubuzione dei generi musicali nel df
lables <- unique(music_dataset$music_genre)
table(music_dataset$music_genre)
# Rimozione delle colonne rappresentanti feature inutili alla classificazione con i modelli
# quindi, principalmente si eliminano i caratteri qualitativi che non saranno trasformati in factors
music_dataset <- within(music_dataset, rm('instance_id', 'track_name', 'obtained_date', 'index', 'artist_name'))
dim(music_dataset)
sample_n(music_dataset, 5)
# Codifica delle colonne con valori qualitativi attraverso factors(x, levels)
# Per utilizzare nei modelli le colonne "key" e "mode" si codificano mappandone i valori
# al fine di renderli valori numerici
# "mode" - codifica in valori pari a 1 o 2 (majior o minor)
# "key" - codifica fino a 12 valori (suoni note musicali)
encode_ordinal <- function(x, order = unique(x)) {
x <- as.numeric(factor(x, levels = order, exclude = NULL))
x
}
music_dataset[["key"]] <- encode_ordinal(music_dataset[["key"]])
head(music_dataset)
music_dataset[["mode"]] <- encode_ordinal(music_dataset[["mode"]])
head(music_dataset)
music_dataset$tempo <- as.double(music_dataset$tempo)
head(music_dataset)
# Trasformazione delle lables da type: chr a type: factor
music_dataset$music_genre = as.factor(music_dataset$music_genre)
str(music_dataset)
dim(music_dataset)
# Verifica e rimozione dei valori NA dopo la codifica delle features "key" e "mode"
music_dataset <- na.omit(music_dataset)
music_dataset <- music_dataset[complete.cases(music_dataset),]
dim(music_dataset[rowSums(is.na(music_dataset)) > 0, ])
music_dataset %>% drop_na()
head(music_dataset)
z_scores <- as.data.frame(sapply(music_dataset, function(music_dataset) (abs(music_dataset-mean(music_dataset))/sd(music_dataset))))
no_outliers <- z_scores[!rowSums(z_scores>3), ]
head(no_outliers)
music_dataset <- music_dataset[ , c("music_genre")]
